server:
  host: "0.0.0.0"
  port: 8081

database:
  url: "postgres://upal:upal@localhost:5432/upal?sslmode=disable"

# AI Providers â€” uncomment and configure the ones you need.
# Each provider name becomes the prefix for model IDs (e.g., "openai/gpt-4o").
providers:
  # OpenAI (also works for any OpenAI-compatible API like Ollama, LM Studio)
  # openai:
  #   type: openai
  #   url: "https://api.openai.com/v1"
  #   api_key: "sk-..."
  #
  # Ollama (local LLMs via OpenAI-compatible API)
  ollama:
    type: openai
    url: "http://localhost:11434/v1"
    api_key: ""
  #
  # Anthropic (Claude)
  # anthropic:
  #   type: anthropic
  #   url: "https://api.anthropic.com"
  #   api_key: "sk-ant-..."
  #
  # Claude Code (uses claude CLI subscription, no API key needed)
  claude:
    type: claude-code
  #
  # Google Gemini (text)
  gemini:
    type: gemini
    url: "https://generativelanguage.googleapis.com"
    api_key: "AIzaSyAUerVuk-jjN_N3r3lx_r3kANcUHwgAoRQ"
  #
  # Google Gemini Image Generation (Nano Banana)
  nano-banana:
    type: gemini-image
    api_key: "AIzaSyAUerVuk-jjN_N3r3lx_r3kANcUHwgAoRQ"
  #
  # Z-IMAGE local inference server (run: python scripts/zimage_server.py)
  zimage:
    type: zimage
    url: "http://localhost:8090"

mcp_servers: {}
